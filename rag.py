import chromadb
import google.generativeai as genai
from openai import OpenAI

# ========== API é‡‘é‘°è¨­å®š ==========
# âœ… Gemini Embedding API Key
genai.configure(api_key="")

# âœ… OpenAI GPT å›ç­”ç”¨ API Key
client = OpenAI(api_key="")

# ========== åµŒå…¥ç”¢ç”Ÿï¼ˆä½¿ç”¨ Geminiï¼‰ ==========
def get_gemini_embedding(texts):
    if isinstance(texts, str):
        texts = [texts]
    embs = []
    for text in texts:
        res = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="semantic_similarity"
        )
        embs.append(res["embedding"])
    return embs

# ========== è¼‰å…¥ Chroma è³‡æ–™åº« ==========
client_chroma = chromadb.PersistentClient(path="./chroma_db")
thread_id = "thread_1234"  # Collection åç¨±ï¼ˆä¹‹å‰ upload.py å»ºç«‹éï¼‰
collection = client_chroma.get_collection(name=thread_id)

# ========== å•ç­”ä¸»è¿´åœˆ ==========
while True:
    user_q = input("\nè«‹è¼¸å…¥ä½ çš„å•é¡Œï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰ï¼š")
    if user_q.strip().lower() == "exit":
        break

    # 1. å°‡å•é¡Œè½‰ç‚ºå‘é‡
    q_emb = get_gemini_embedding(user_q)[0]

    # 2. èªæ„æŸ¥è©¢æœ€è¿‘çš„ 3 ç­†è³‡æ–™
    results = collection.query(query_embeddings=[q_emb], n_results=3)
    top_contexts = results['documents'][0]

    # å»ºç«‹æœ‰æ¨™è¨»ä¾†æºçš„æ®µè½
    context_parts = []
    for i in range(len(top_contexts)):
        doc = top_contexts[i]
        doc_id = results['ids'][0][i]
        meta = results['metadatas'][0][i]
        user = meta.get("user", "æœªçŸ¥ä½¿ç”¨è€…")

        context_parts.append(f"ã€ç•™è¨€ {doc_id}ï½œ{user}ã€‘\n{doc}")

    # 3. çµ„ prompt
    prompt = (
        "æ ¹æ“šä»¥ä¸‹ç•™è¨€å…§å®¹ä½œç‚ºåƒè€ƒï¼Œè«‹å›ç­”ç”¨æˆ¶çš„å•é¡Œï¼š\n\n"
        "ã€ç›¸é—œç•™è¨€ã€‘\n"
        + "\n".join(context_parts)
        + f"\n\nã€å•é¡Œã€‘{user_q}\nè«‹è©³ç´°å›è¦†ï¼š"
    )

    print("\nğŸ“¦ å‚³é€çµ¦ GPT çš„ Promptï¼š\n", prompt)

    # 4. å‘¼å« OpenAI GPT ç”¢ç”Ÿå›ç­”ï¼ˆæ–°ç‰ˆ SDK å¯«æ³•ï¼‰
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹çŸ¥è­˜å‹åŠ©æ‰‹"},
                {"role": "user", "content": prompt}
            ]
        )

        print("\nğŸ¤– AI å›ç­”ï¼š\n", response.choices[0].message.content)

    except Exception as e:
        print("âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š", e)

print("çµæŸç¨‹å¼ã€‚")
